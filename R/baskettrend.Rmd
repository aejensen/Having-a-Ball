---
title: "basketball"
date: "11/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r cars}
url <- "https://www.basketball-reference.com/boxscores/pbp/202010090LAL.html"
library("rvest")
library("tidyverse")


harvest_data <- function(url) {

  raw_data <-
    url %>% 
    read_html() %>% 
    html_table() %>% 
    as.data.frame()

  names(raw_data) <- c("time", "text", "change", "score", "change2", "text2")

  val1 <- as.numeric(raw_data$change) 
  val2 <- as.numeric(raw_data$change2)
   
  keeptimes <- ((!is.na(val1)) | (!is.na(val2)))
   
  scorediff <- cumsum(ifelse(is.na(val1), 0, val1)) - cumsum(ifelse(is.na(val2), 0, val2))
   
  scorediff <- scorediff[keeptimes]

  splitl <- stringr::str_split(raw_data$time, ":")
   for (i in 1:length(splitl)) {
       splitl[[i]]
   }


   part1 <- sapply(stringr::str_split(raw_data$time, ":"), function(i) {
       ifelse(length(i)==1, NA, 12-as.numeric(i[1]) -
              as.numeric(stringr::str_split(i[2], "\\.")[[1]][1])/60 -
              as.numeric(stringr::str_split(i[2], "\\.")[[1]][2])/60/100
       )
   })
   
   # Now convert quarters
   quarter <- 0
   part2 <- part1
   for (i in 1:length(part1)) {
       if (!is.na(part2[i]) & part2[i]==0) {
           quarter <- quarter +1
       }
       part2[i] <- part1[i]+12*(quarter-1)
   }

  # part1 <- part1[keeptimes]
   

  DF <- data.frame(time=c(0, part2[keeptimes]), 
                   scorediff=c(0, scorediff))
  
  DF
  
}

harvest_data(url)

```


## Heavy wrangling

Need to fix times and scores

First we try to fix time
```{r}
url2 <- "https://www.basketball-reference.com/leagues/NBA_2020_games-october.html"

    url2 %>% 
    read_html() %>% 
    html_table() %>% 
    as.data.frame()

    
    
    url2 %>% 
    read_html() %>% 
        html_nodes("#div_schedule.overthrow") %>% 
        as.data.frame()
    
```

# Grab all pages

(Don't run unless you need a bit bowl of coffee)

```{r eval=FALSE}
pages2019 <- expand.grid(2019, # Year
                     c(10, 11, 12), # Month 
                     1:31, # Day 
                     c("LAC", "TOR", "NYK", "BRK", "MIN", "CHO", "DEN", "UTA", "LAL", "DAL", "NOP", "WAS", "OKC", "POR", "SAC", "ORL", "ATL", "IND", "CLE", "PHI", "DET", "HOU", "MIA", "MIL", "PHO", "SAS", "GSW", "MEM", "BOS", "CHI")) # Home turf team

pages2020 <- expand.grid(2020, # Year
                     c(10, 1, 2, 3, 7, 8, 9), # Month 
                     1:31, # Day 
                     c("LAC", "TOR", "NYK", "BRK", "MIN", "CHO", "DEN", "UTA", "LAL", "DAL", "NOP", "WAS", "OKC", "POR", "SAC", "ORL", "ATL", "IND", "CLE", "PHI", "DET", "HOU", "MIA", "MIL", "PHO", "SAS", "GSW", "MEM", "BOS", "CHI")) # Home turf team

pages <- rbind(pages2019, pages2020)


urls <- sprintf('%s%02d%02d0%s.html', pages[,1], pages[,2], pages[,3], pages[,4])

# Start grabbing the info

results <- lapply(urls, function(i) {
    cat(".")
    # Maybe insert a sleep or risk getting blacklisted?
    tryCatch(
        harvest_data(paste0("https://www.basketball-reference.com/boxscores/pbp/", i)),
  error=function(e){NA})
})



```

# Use the saved data

```{r}

load("../data/nba20192020.rda")
match_results <- sapply(results, function(i) !any(is.na(i)))
sum(match_results)

```


