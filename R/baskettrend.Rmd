---
title: "basketball"
date: "11/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup}
# Packages
library("rvest")
library("tidyverse")
library("parallel")

# Silly URLs to try out
url <- "https://www.basketball-reference.com/boxscores/pbp/202010090LAL.html"
url <- "https://www.basketball-reference.com/boxscores/pbp/201910220TOR.html"
url <- "https://www.basketball-reference.com/boxscores/pbp/2asdasd01910220TOR.html"


# Give URL as input - harvest play-by-play data
# Return data frame with two columns - time and score difference
# And som attributes with extra information
harvest_data <- function(url) {

  # Get the table with the match play-by-play results
  valid_page <- tryCatch(
    url_html <- url %>% url() %>% read_html(),
    error=function(e){NA}
  )

  if (is.na(valid_page)) {
    return(NA)
  }

  raw_data <-
    url_html %>% 
    html_table() %>% 
    as.data.frame()
  
  # Now do a bit of data wrangling
  names(raw_data) <- c("time", "text", "change", "score", "change2", "text2")

  val1 <- as.numeric(raw_data$change) 
  val2 <- as.numeric(raw_data$change2)
  
  # Only keep the time points where a scoring happens 
  # Find the relevant indices
  keeptimes <- ((!is.na(val1)) | (!is.na(val2)))
   
  scorediff <- cumsum(ifelse(is.na(val1), 0, val1)) - cumsum(ifelse(is.na(val2), 0, val2))
   
  scorediff <- scorediff[keeptimes]

#  splitl <- stringr::str_split(raw_data$time, ":")
#   for (i in 1:length(splitl)) {
#       splitl[[i]]
#   }


   part1 <- sapply(stringr::str_split(raw_data$time, ":"), function(i) {
       ifelse(length(i)==1, NA, 12-as.numeric(i[1]) -
              as.numeric(stringr::str_split(i[2], "\\.")[[1]][1])/60 -
              as.numeric(stringr::str_split(i[2], "\\.")[[1]][2])/60/100
       )
   })
   
   # Now convert quarters
   quarter <- 0
   part2 <- part1
   for (i in 1:length(part1)) {
       if (!is.na(part2[i]) & part2[i]==0) {
           quarter <- quarter +1
       }
       # Fix the problem with over time
       if (!is.na(part2[i]) & part2[i]==7 & i>1) {
            if (is.na(part2[i-1])) {
             quarter <- quarter +1
            }
       }
       part2[i] <- part1[i]+12*(quarter-1) - 7*(quarter>4) # Overtime is only 5 minutes. Subtract that
   }
   
   # Get additional information that might be of interest
   pattern <- "(.+?) at (.+?) Play-By-Play, (.+)"

   meta_info <- url_html %>% 
       html_nodes("h1") %>% 
       html_text() %>% 
       stringr::str_match(pattern)


  DF <- data.frame(time=c(0, part2[keeptimes]), 
                   scorediff=c(0, scorediff)) %>%
      dplyr::group_by(time) %>% # Kollaps tider fra straffekast
      dplyr::filter(row_number() == n()) %>% 
      ungroup()

  attr(DF, "home") <- meta_info[1,3]
  attr(DF, "away") <- meta_info[1,2]
  attr(DF, "date") <- meta_info[1,4]
      
  DF
  
}

harvest_data(url)

```


```{r}
get_attendence_data <- function() {
    
}
```



## Attendance scores

Get attendance scores

```{r}
url2 <- "https://www.basketball-reference.com/leagues/NBA_2020_games-october.html"

replaceCommas<-function(x){
  x<-as.numeric(gsub("\\,", "", x))
}

attdata <- 
    url2 %>% 
    read_html() %>% 
    html_table() %>% 
    as.data.frame() %>% 
    dplyr::select(Date, Attend., Home.Neutral) %>% 
    dplyr::mutate(attend=replaceCommas(Attend.),
                  date=stringr::str_sub(Date, 6)) %>% 
    dplyr::mutate(ddd = lubridate::mdy(date)) %>% 
    dplyr::filter(!is.na(ddd)) %>% 
    dplyr::select(-Date, -Attend.) 

    part1 <- 
    lapply(results, function(i) { 
        data.frame(ddd=lubridate::mdy(attr(i, "date")),
                   home=attr(i, "home"))
                   }) %>% 
    do.call("rbind", args=.) %>% 
    mutate(index = row_number())
    


```

# Grab all pages

(Don't run unless you need a bit bowl of coffee)

```{r eval=FALSE}
pages2019 <- expand.grid(2019, # Year
                     c(10, 11, 12), # Month 
                     1:31, # Day 
                     c("LAC", "TOR", "NYK", "BRK", "MIN", "CHO", "DEN", "UTA", "LAL", "DAL", "NOP", "WAS", "OKC", "POR", "SAC", "ORL", "ATL", "IND", "CLE", "PHI", "DET", "HOU", "MIA", "MIL", "PHO", "SAS", "GSW", "MEM", "BOS", "CHI")) # Home turf team

pages2020 <- expand.grid(2020, # Year
                     c(10, 1, 2, 3, 7, 8, 9), # Month 
                     1:31, # Day 
                     c("LAC", "TOR", "NYK", "BRK", "MIN", "CHO", "DEN", "UTA", "LAL", "DAL", "NOP", "WAS", "OKC", "POR", "SAC", "ORL", "ATL", "IND", "CLE", "PHI", "DET", "HOU", "MIA", "MIL", "PHO", "SAS", "GSW", "MEM", "BOS", "CHI")) # Home turf team

pages <- rbind(pages2019, pages2020)


urls <- sprintf('%s%02d%02d0%s.html', pages[,1], pages[,2], pages[,3], pages[,4])

# Start grabbing the info

results <- mclapply(urls, function(i) {
    cat(".")
    harvest_data(paste0("https://www.basketball-reference.com/boxscores/pbp/", i))
}, mc.cores=3L)



```

# Use the saved data

```{r}

load("../data/nba20192020.rda")
match_results <- sapply(results, function(i) !any(is.na(i)))
sum(match_results)


lapply(results, function(i) { ifelse(is.na(i), NA,  any(diff(i$time)<0))})

time_problems <- sapply(results, function(i) { ifelse(length(i)==1, NA, any(diff(i[1])<0)) } )

time_problems == TRUE

keepsie <- sapply(time_problems, function(i) {!is.na(i)})
any(time_problems[keepsie])
```


